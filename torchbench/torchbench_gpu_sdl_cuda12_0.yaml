version: '2.0'
services:
  gpu-test:
    image: docker.io/thumperai/torchbench:v0.0.10-cuda-12.0-dev
    expose:
      - port: 8888
        as: 80
        to:
          - global: true
    cmd:
      - '"jupyter", "lab", "--ip=0.0.0.0", "--port=8888", "--allow-root", "--no-browser"'
    env:
      - JUPYTER_TOKEN=passwd
profiles:
  compute:
    gpu-test:
      resources:
        cpu:
          units: 1
        memory:
          size: 20Gi
        gpu:
          units: 1
          attributes:
            vendor:
              nvidia:
                - model: a40
                - model: a10
                - model: 4090
                - model: 3090Ti
                - model: 4080
                - model: 3090
                - model: h100
                - model: a100
                - model: v100
                - model: 3060
                - model: p100
                - model: 4000
                - model: a4000
                - model: 2070
                - model: 1080
                - model: 1080Ti

        storage:
          - size: 100Gi
  placement:
    westcoast:
      pricing:
        gpu-test:
          denom: uakt
          amount: 100000
deployment:
  gpu-test:
    westcoast:
      profile: gpu-test
      count: 1